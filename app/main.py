import streamlit as st
from strands import Agent, tool
from strands.models import BedrockModel
from mcp.client.streamable_http import streamablehttp_client
from strands.tools.mcp import MCPClient
from datetime import datetime
import pytz
import asyncio
import os
from components import get_link_icons_html, get_tool_list_html

st.set_page_config(
    page_title="Strands Agent with MCP Server on Lambda", 
    page_icon="ğŸª¢", 
)

st.title("ğŸª¢ AWS Detective Agent")

with st.sidebar:
    if st.button("ğŸ—‘ï¸ Clear Chat", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.divider()
    
    st.markdown("### Link")
    st.markdown(get_link_icons_html(), unsafe_allow_html=True)
    st.divider()
    
    st.markdown("### Tool List")
    st.markdown(get_tool_list_html(), unsafe_allow_html=True)

if 'messages' not in st.session_state:
    st.session_state.messages = []

MCP_URL = os.environ["MCP_URL"]

@tool
def get_current_date(timezone: str = "Asia/Tokyo", format: str = "%Y-%m-%d %H:%M:%S"):
    tz = pytz.timezone(timezone)
    current_time = datetime.now(tz)
    return current_time.strftime(format)

bedrock_model = BedrockModel(
    model_id='apac.anthropic.claude-3-5-sonnet-20241022-v2:0',
    region_name='ap-northeast-1',
    temperature=0.7,
    max_tokens=4000
)

system_prompt = """ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„AWSã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆå…¼æ¢åµã§ã™ã€‚
CloudTrailã‚¤ãƒ™ãƒ³ãƒˆã®åˆ†æã‚„ã€AWSãƒªã‚½ãƒ¼ã‚¹ã®ç›£è¦–ã«é–¢ã™ã‚‹è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ã€‚
å£èª¿ã¯å°èª¬ã®æ¢åµã®ã‚ˆã†ã«ã—ã¦ã€æ•¬èªã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
ä¾‹ï¼‰ã€Œã‚ˆã‹ã‚ã†ã€ã€Œã¾ãšã¯ä»Šæ—¥ã®æ—¥æ™‚ã‚’ã¯ã£ãã‚Šã•ã›ã‚ˆã†ã€ã€Œãã‚Œã§ã¯èª¿æŸ»ã‚’é–‹å§‹ã—ã‚ˆã†ã€ã€Œâ—‹â—‹ã•ã‚“ã®æ“ä½œå±¥æ­´ã ãŒã€ãŠãŠã‚ˆãã“ã‚“ãªã‚‚ã®ã ã‚ã†ã€

åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«:
- lookup_cloudtrail_events: CloudTrailã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œç´¢ (MCPã‚µãƒ¼ãƒãƒ¼çµŒç”±)
- get_current_date: ç¾åœ¨ã®æ—¥ä»˜ã¨æ™‚åˆ»ã‚’å–å¾—

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒCloudTrailã‚„AWSã®æ´»å‹•ã«ã¤ã„ã¦è³ªå•ã—ãŸå ´åˆã¯ã€é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
ç¾åœ¨ã®æ—¥ä»˜ã‚„æ™‚åˆ»ãŒå¿…è¦ãªå ´åˆã¯ã€get_current_dateãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
æ—¥æ™‚ã‚’æŒ‡å®šã™ã‚‹éš›ã¯ã€ISO 8601å½¢å¼ï¼ˆä¾‹: "2025-07-10T00:00:00Z"ï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"""

async def stream_agent_response(agent, prompt: str, container):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°"""
    try:
        text_holder = container.empty()
        text_buffer = ""
        displayed_tools = set()
        
        async for chunk in agent.stream_async(prompt):
            tool_id, tool_name = extract_tool_from_chunk(chunk)
            
            if tool_id and tool_name and tool_id not in displayed_tools:
                displayed_tools.add(tool_id)
                
                if text_buffer:
                    text_holder.markdown(text_buffer)
                    text_buffer = ""
                
                container.info(f"ğŸ” *{tool_name}* ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œä¸­")
                text_holder = container.empty()
            
            chunk_text = extract_text_from_chunk(chunk)
            if chunk_text:
                text_buffer += chunk_text
                text_holder.markdown(text_buffer + "ğŸ—•")
        
        if text_buffer:
            text_holder.markdown(text_buffer)
            return text_buffer
            
    except Exception as e:
        container.error(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        fallback_response = agent(prompt)
        container.markdown(fallback_response)
        return fallback_response


def extract_tool_from_chunk(chunk):
    """ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ãƒ„ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—"""
    event = chunk.get('event', {})
    
    content_block_start = event.get('contentBlockStart')
    if not content_block_start:
        return None, None
    
    tool_use = content_block_start.get('start', {}).get('toolUse', {})
    return tool_use.get('toolUseId'), tool_use.get('name')


def extract_text_from_chunk(chunk):
    """ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
    if direct_text := chunk.get('data'):
        return direct_text
    
    deta = chunk.get('deta', {})
    if delta_text := deta.get('text'):
        return delta_text
    
    return ""


for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("ğŸ•µï¸â€â™‚ï¸èª¿æŸ»ä¸­â€¦"):
            mcp_client = MCPClient(lambda: streamablehttp_client(MCP_URL))
            with mcp_client:
                mcp_tools = mcp_client.list_tools_sync()
                all_tools = list(mcp_tools) + [get_current_date]
                
                agent = Agent(
                    model=bedrock_model,
                    tools=all_tools,
                    system_prompt=system_prompt
                )
                
                # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
                loop = asyncio.new_event_loop()
                response = loop.run_until_complete(stream_agent_response(agent, prompt, st.container()))
                loop.close()
                
                if response:
                    st.session_state.messages.append({"role": "assistant", "content": response}) 